/**
 * VLM (Vision Language Model) å›¾ç‰‡åˆ†ææ¨¡å—
 * ä½¿ç”¨æ™ºå¢å¢ API (Qwen VL) é¢„åˆ†æå›¾ç‰‡å†…å®¹ï¼Œæå–æ–‡å­—å’Œç»“æ„åŒ–æè¿°
 * è¿™æ˜¯ä¸€ä¸ªå¯é€‰åŠŸèƒ½ï¼Œéœ€è¦è®¾ç½® ZZZ_API_KEY ç¯å¢ƒå˜é‡
 */

import { logger } from './logger';
import type { VLMAnalysisResult, ImageData } from '../types';

/**
 * æ™ºå¢å¢ API é…ç½®
 */
const ZZZ_API_URL = 'https://api.zhizengzeng.com/v1/chat/completions';
const ZZZ_VLM_MODEL = 'qwen3-vl-235b-a22b-thinking';

/**
 * æ£€æŸ¥ VLM åŠŸèƒ½æ˜¯å¦å¯ç”¨
 */
export function isVLMAvailable(): boolean {
  return !!process.env.ZZZ_API_KEY;
}

/**
 * ä½¿ç”¨ VLM åˆ†æå•å¼ å›¾ç‰‡
 *
 * @param imageBase64 å›¾ç‰‡çš„ Base64 ç¼–ç 
 * @param mimeType å›¾ç‰‡ MIME ç±»å‹
 * @param customPrompt è‡ªå®šä¹‰åˆ†ææç¤ºè¯ï¼ˆå¯é€‰ï¼‰
 * @returns VLM åˆ†æç»“æœ
 */
export async function analyzeImageWithVLM(
  imageBase64: string,
  mimeType: string = 'image/jpeg',
  customPrompt?: string
): Promise<VLMAnalysisResult> {

  if (!process.env.ZZZ_API_KEY) {
    throw new Error('VLM åŠŸèƒ½ä¸å¯ç”¨ï¼šè¯·è®¾ç½® ZZZ_API_KEY ç¯å¢ƒå˜é‡');
  }

  // é»˜è®¤æç¤ºè¯ï¼šæå–æ–‡å­—å’Œæè¿°å›¾ç‰‡å†…å®¹
  const defaultPrompt = `è¯·è¯¦ç»†åˆ†æè¿™å¼ å›¾ç‰‡ï¼Œå¹¶æä¾›ä»¥ä¸‹ä¿¡æ¯ï¼š

1. å›¾ç‰‡ä¸­æ˜¯å¦åŒ…å«æ–‡å­—ï¼Ÿå¦‚æœæœ‰ï¼Œè¯·é€å­—æå–æ‰€æœ‰å¯è§æ–‡å­—ï¼ˆåŒ…æ‹¬ä¸­è‹±æ–‡ï¼‰
2. å›¾ç‰‡çš„ä¸»è¦å†…å®¹å’Œåœºæ™¯æè¿°
3. å›¾ç‰‡ä¸­çš„å…³é”®å¯¹è±¡ã€å…ƒç´ æˆ–ä¸»é¢˜
4. å›¾ç‰‡çš„ç±»å‹ï¼ˆå¦‚ï¼šæˆªå›¾ã€ç…§ç‰‡ã€å›¾è¡¨ã€è®¾è®¡ç¨¿ç­‰ï¼‰

è¯·ä»¥ç»“æ„åŒ–çš„æ–¹å¼å›ç­”ï¼Œæ¸…æ™°æ˜äº†ã€‚`;

  const prompt = customPrompt || defaultPrompt;

  try {
    logger.debug(`ğŸ” ä½¿ç”¨æ™ºå¢å¢ VLM (${ZZZ_VLM_MODEL}) åˆ†æå›¾ç‰‡...`);

    // æ„å»ºç¬¦åˆ OpenAI vision æ ¼å¼çš„è¯·æ±‚
    const requestBody = {
      model: ZZZ_VLM_MODEL,
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'image_url',
              image_url: {
                url: `data:${mimeType};base64,${imageBase64}`
              }
            },
            {
              type: 'text',
              text: prompt
            }
          ]
        }
      ],
      max_tokens: 1024
    };

    // è°ƒç”¨æ™ºå¢å¢ API
    logger.debug(`è°ƒç”¨ API: ${ZZZ_API_URL}`);
    logger.debug(`è¯·æ±‚ä½“å¤§å°: ${JSON.stringify(requestBody).length} å­—èŠ‚`);

    const response = await fetch(ZZZ_API_URL, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${process.env.ZZZ_API_KEY}`
      },
      body: JSON.stringify(requestBody)
    });

    logger.debug(`å“åº”çŠ¶æ€: ${response.status} ${response.statusText}`);

    const data = await response.json();

    // è°ƒè¯•ï¼šæ‰“å°å®Œæ•´å“åº”
    logger.debug('æ™ºå¢å¢ API åŸå§‹å“åº”:', JSON.stringify(data, null, 2));

    // æ£€æŸ¥ API é”™è¯¯
    if (data.error) {
      const errorMsg = data.error.message || JSON.stringify(data.error);
      logger.error('æ™ºå¢å¢ API é”™è¯¯:', errorMsg);
      throw new Error(`æ™ºå¢å¢ API é”™è¯¯: ${errorMsg}`);
    }

    // æ£€æŸ¥ HTTP çŠ¶æ€
    if (!response.ok) {
      throw new Error(`æ™ºå¢å¢ API è°ƒç”¨å¤±è´¥: ${response.status} ${JSON.stringify(data)}`);
    }

    // æå–å“åº”æ–‡æœ¬
    const responseText = data.choices?.[0]?.message?.content || '';

    if (!responseText) {
      logger.error('VLM å“åº”ç»“æ„å¼‚å¸¸:', JSON.stringify(data, null, 2));
      throw new Error('VLM è¿”å›ç©ºå“åº”ï¼Œå“åº”ç»“æ„: ' + JSON.stringify(data));
    }

    logger.debug(`âœ… VLM åˆ†æå®Œæˆ (ä½¿ç”¨ tokens: ${data.usage?.total_tokens || 'N/A'})`);

    // è§£æç»“æœ
    const hasText = responseText.toLowerCase().includes('æ–‡å­—') ||
                    responseText.toLowerCase().includes('text') ||
                    /åŒ…å«|å­˜åœ¨|æœ‰.*æ–‡å­—/.test(responseText);

    // ç®€å•æå–æ–‡æœ¬å†…å®¹
    const textContent = extractTextFromVLMResponse(responseText);
    const detectedObjects = extractObjectsFromVLMResponse(responseText);

    return {
      hasText,
      textContent,
      description: responseText,
      detectedObjects,
      confidence: 0.85
    };

  } catch (error: any) {
    logger.error(`VLM åˆ†æå¤±è´¥: ${error.message}`);
    logger.error(`é”™è¯¯è¯¦æƒ…: ${JSON.stringify(error, Object.getOwnPropertyNames(error))}`);

    // æä¾›æ›´å‹å¥½çš„é”™è¯¯æç¤º
    if (error.message.includes('fetch failed')) {
      throw new Error(`VLM API è°ƒç”¨å¤±è´¥ (ç½‘ç»œé”™è¯¯): ${error.message}. è¯·æ£€æŸ¥: 1) ç½‘ç»œè¿æ¥, 2) API ç«¯ç‚¹æ˜¯å¦æ­£ç¡®, 3) æ˜¯å¦éœ€è¦ä»£ç†`);
    }

    throw new Error(`VLM åˆ†æå¤±è´¥: ${error.message}`);
  }
}

/**
 * æ‰¹é‡åˆ†æå›¾ç‰‡
 *
 * @param images å›¾ç‰‡æ•°æ®æ•°ç»„
 * @param customPrompt è‡ªå®šä¹‰åˆ†ææç¤ºè¯ï¼ˆå¯é€‰ï¼‰
 * @returns åˆ†æç»“æœæ•°ç»„
 */
export async function analyzeImages(
  images: ImageData[],
  customPrompt?: string
): Promise<VLMAnalysisResult[]> {
  if (!isVLMAvailable()) {
    logger.warn('VLM åŠŸèƒ½ä¸å¯ç”¨ï¼Œè·³è¿‡å›¾ç‰‡åˆ†æ');
    return [];
  }

  const results: VLMAnalysisResult[] = [];

  for (let i = 0; i < images.length; i++) {
    try {
      logger.debug(`åˆ†æç¬¬ ${i + 1}/${images.length} å¼ å›¾ç‰‡...`);

      const result = await analyzeImageWithVLM(images[i].base64, images[i].mimeType, customPrompt);
      results.push(result);

      // æ·»åŠ å»¶è¿Ÿä»¥é¿å… API é™æµ
      if (i < images.length - 1) {
        await new Promise(resolve => setTimeout(resolve, 1000));
      }
    } catch (error: any) {
      logger.error(`ç¬¬ ${i + 1} å¼ å›¾ç‰‡åˆ†æå¤±è´¥: ${error.message}`);
      // æ·»åŠ ç©ºç»“æœ
      results.push({
        hasText: false,
        textContent: '',
        description: `åˆ†æå¤±è´¥: ${error.message}`,
        detectedObjects: [],
        confidence: 0
      });
    }
  }

  return results;
}

/**
 * ä» VLM å“åº”ä¸­æå–æ–‡æœ¬å†…å®¹
 * è¿™æ˜¯ä¸€ä¸ªç®€å•çš„å®ç°ï¼Œå®é™…é¡¹ç›®ä¸­å¯ä»¥ä½¿ç”¨æ›´å¤æ‚çš„ NLP è§£æ
 */
function extractTextFromVLMResponse(response: string): string {
  // æŸ¥æ‰¾åŒ…å«æ–‡å­—æå–çš„éƒ¨åˆ†
  const textMatches = response.match(/æ–‡å­—[ï¼š:]([\s\S]+?)(?=\n\n|\n[0-9]|\n[A-Z]|$)/);
  if (textMatches && textMatches[1]) {
    return textMatches[1].trim();
  }

  // æŸ¥æ‰¾å¼•å·ä¸­çš„æ–‡æœ¬
  const quoteMatches = response.match(/[ã€Œã€"](.*?)[ã€ã€"]/g);
  if (quoteMatches && quoteMatches.length > 0) {
    return quoteMatches.map(m => m.replace(/[ã€Œã€"ã€ã€"]/g, '')).join('\n');
  }

  // å¦‚æœæ‰¾ä¸åˆ°ç‰¹å®šæ ¼å¼ï¼Œå°è¯•æå–åŒ…å«"å†…å®¹"æˆ–"æ–‡æœ¬"çš„æ®µè½
  const contentMatch = response.match(/(?:å†…å®¹|æ–‡æœ¬|æ–‡å­—)[:ï¼š]\s*(.+)/);
  if (contentMatch && contentMatch[1]) {
    return contentMatch[1].trim();
  }

  return '';
}

/**
 * ä» VLM å“åº”ä¸­æå–æ£€æµ‹åˆ°çš„å¯¹è±¡/å…ƒç´ 
 */
function extractObjectsFromVLMResponse(response: string): string[] {
  const objects: string[] = [];

  // å¸¸è§çš„å¯¹è±¡ç±»å‹å…³é”®è¯
  const keywords = [
    'æˆªå›¾', 'screenshot', 'ç…§ç‰‡', 'photo', 'å›¾è¡¨', 'chart',
    'ä»£ç ', 'code', 'æ–‡æ¡£', 'document', 'è®¾è®¡', 'design',
    'ç•Œé¢', 'UI', 'ç½‘é¡µ', 'webpage', 'æµ·æŠ¥', 'poster',
    'å…¬å¼', 'formula', 'è¡¨æ ¼', 'table', 'æµç¨‹å›¾', 'flowchart'
  ];

  for (const keyword of keywords) {
    if (response.toLowerCase().includes(keyword.toLowerCase())) {
      objects.push(keyword);
    }
  }

  return [...new Set(objects)];  // å»é‡
}

/**
 * ä¼°ç®— VLM API è°ƒç”¨æˆæœ¬
 *
 * @param imageCount å›¾ç‰‡æ•°é‡
 * @param avgTokensPerImage æ¯å¼ å›¾ç‰‡å¹³å‡ token æ•°ï¼ˆé»˜è®¤çº¦ 1500ï¼‰
 * @returns ä¼°ç®—æˆæœ¬ï¼ˆäººæ°‘å¸å…ƒï¼‰
 */
export function estimateVLMCost(
  imageCount: number,
  avgTokensPerImage: number = 1500
): { inputCost: number; outputCost: number; totalCost: number } {
  // Qwen VL å®šä»·ï¼ˆéœ€è¦æ ¹æ®æ™ºå¢å¢å®é™…å®šä»·è°ƒæ•´ï¼Œè¿™é‡Œä½¿ç”¨ä¼°ç®—å€¼ï¼‰
  // å‡è®¾ï¼šÂ¥0.001/1K tokensï¼ˆè¾“å…¥ï¼‰ï¼ŒÂ¥0.002/1K tokensï¼ˆè¾“å‡ºï¼‰
  const inputCostPerKToken = 0.001;
  const outputCostPerKToken = 0.002;

  const avgOutputTokens = 500;  // å¹³å‡è¾“å‡º 500 tokens

  const totalInputTokens = imageCount * avgTokensPerImage;
  const totalOutputTokens = imageCount * avgOutputTokens;

  const inputCost = (totalInputTokens / 1000) * inputCostPerKToken;
  const outputCost = (totalOutputTokens / 1000) * outputCostPerKToken;
  const totalCost = inputCost + outputCost;

  return {
    inputCost,
    outputCost,
    totalCost
  };
}

/**
 * æ‰“å° VLM æˆæœ¬ä¼°ç®—
 */
export function printVLMCostEstimate(imageCount: number): void {
  const cost = estimateVLMCost(imageCount);

  logger.info(`\nğŸ’° VLM API æˆæœ¬ä¼°ç®— (${imageCount} å¼ å›¾ç‰‡):`);
  logger.info(`   è¾“å…¥æˆæœ¬: Â¥${cost.inputCost.toFixed(4)}`);
  logger.info(`   è¾“å‡ºæˆæœ¬: Â¥${cost.outputCost.toFixed(4)}`);
  logger.info(`   æ€»è®¡: Â¥${cost.totalCost.toFixed(4)}\n`);
}
